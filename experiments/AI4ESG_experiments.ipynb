{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:40.917246Z",
     "start_time": "2024-02-21T11:02:40.912755Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../backend')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai4esg-MyrZEbvC-py3.11\\Lib\\site-packages\\pydantic\\_internal\\_config.py:322: UserWarning: Valid config keys have changed in V2:\n",
      "* 'orm_mode' has been renamed to 'from_attributes'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_doc length: 10274\n",
      "\n",
      "Live Nation Entertainment Privacy Policy - Your Privacy Rights Effective July 20, 2012 (last updated October 08, 2013)\n",
      "This Privacy Policy applies to the sites and apps where it appears. This Policy describes how we treat personal information we collect both online and offline. This includes on our websites or in our apps. It also includes at our box offices or in phone or email interactions you have with us. If you live in Canada, please read our Canadian Privacy Policy.\n",
      "We collect information from and about you. Contact information. For example, we might collect your name and street address. We might also collect your phone number or email.\n",
      "Payment and billing information. For example, we collect your credit card number and zip code when you buy a ticket.\n",
      "Information you post. For example, we collect information you post in a public space on our website or on a third-party social media site.\n",
      "Demographic information. We may collect information about events you like or products you buy. We might collect this as part of a survey, for example.\n",
      "Other information. If you use our website, we may collect information about the browser you're using. We might look at what site you came from, or what site you visit when you leave us. If you use our mobile app, we may collect your GPS location or your device's unique identifier. We might also collect the type of mobile device you are using, or the version of the operating system your computer or device is running. We might look at how often you use the app and where you downloaded it.\n",
      "We collect information in different ways. We collect information directly from you. For example, if you register for a promotion or buy tickets. We also collect information if you post a comment on our websites or ask us a question.\n",
      "We collect information from you passively. We use tracking tools like browser cookies and web beacons. To learn more about these tools and to control them, please click here.\n",
      "We get information about you from third parties. For example, if you use an integrated social media feature on our websites or mobile applications. The third-party social media site will give us certain information about you. This could include your name and email address. Your activities on our sites and apps may be posted to the social media platforms.\n",
      "We use information as disclosed and described here. We use information to respond to your requests or questions. For example, we might use your information to confirm your registration for an event or contest. If you give us your friend's information, we will only use it to provide services you requested.\n",
      "We use information to improve our products and services. We might use your information to customize your experience with us. This could include displaying content based upon your preferences.\n",
      "We use information to look at site trends and customer interests. We may use your information to make our website and products better. We may combine information we get from you with information about you we get from third parties.\n",
      "We use information for security purposes. We may use information to protect our company, our customers, or our websites.\n",
      "We use information for marketing purposes. For example, we might send you information about special promotions or offers. We might also tell you about new features or products. These might be our own offers or products, or third-party offers or products we think you might find interesting. Or, for example, if you buy tickets from us we'll enroll you in our newsletter. We may use push notifications and your location information on our mobile apps to send you alerts regarding local events. To learn about your choices for these communications, read the choices section below.\n",
      "We use information to send you transactional communications. For example, we might send you emails about your account or a ticket purchase. We might also contact you about this policy or our website terms.\n",
      "We use information as otherwise permitted by law.\n",
      "We may share information with third parties. We will share information within the Live Nation family of companies. This may include Ticketmaster and Live Nation-owned or operated venues, for example.\n",
      "We will share information with third parties who perform services on our behalf. For example, we share information with vendors who help us manage our online registration process or who fulfill your purchases. Some vendors may be located outside of the United States.\n",
      "We will share information with our business partners. This includes a third party who provides or sponsors an event, or who operates a venue where we hold events. Our partners use the information we give them as described in their privacy policies. You should read those polices to learn how they treat your information.\n",
      "We may share information if we think we have to in order to comply with the law or to protect ourselves. For example, we will share information to respond to a court order or subpoena. We may also share it if a government agency or investigatory body requests. Or, we might also share information when we are investigating potential fraud. This might include fraud we think has happened during a sweepstakes or promotion.\n",
      "We may share information with any successor to all or part of our business. For example, if part of our business is sold we may give our customer list as part of that transaction.\n",
      "We may share your information for reasons not described in this policy. We will tell you before we do this.\n",
      "You have certain choices about how we use your information. You can opt out of receiving our marketing emails. To stop receiving our promotional emails, click here or follow the instructions in any promotional message you get from us. Your device settings should provide you with instructions on how to turn off push notifications. It may take about ten days to process your request. Don't worry! Even if you opt out of getting marketing messages, we will still be sure to send you transactional messages. For example, we may still contact you about your orders.\n",
      "You can modify information you have given us. To correct or delete information or update account settings, log into your account and follow the instructions. We make changes as soon as we can. This information may stay in our backup files. If we cannot make the changes you want, we will let you know and explain why. If you contact us requesting access to your information, we will respond within 30 days.\n",
      "You can control cookies and tracking tools. To learn how to manage how we - and our vendors - use cookies and other tracking tools, please click here.\n",
      "You can control tools on your mobile devices. For example, you can turn off the GPS locator or push notifications on your phone. Each push notification has an \"unsubscribe\" link.\n",
      "Your California Privacy Rights. If you live in California and have an established business relationship with us, you can request a list of the personal information we have shared with third parties for their marketing purposes. We will also give you a list of the third parties that have received your information. You can make a request one time each year.\n",
      "To exercise your rights, you can email us or write to us at the address below. Mention in your letter that you are making a \"California Shine the Light\" inquiry. We will respond within 30 days.\n",
      "These sites and apps are not intended for children. Our sites and apps are meant for adults. We do not knowingly collect personally identifiable information from children under 13. If you are a parent or legal guardian and think your child under 13 has given us information, you can email us here. You can also write to us at the address listed at the end of this policy. Please mark your inquiries \"COPPA Information Request.\"\n",
      "Learn more about COPPA here.\n",
      "We use standard security measures. We have security measures in place to protect your information. The standard security measures we use will depend on the type of information collected. However, the Internet is not 100% secure. We cannot promise that your use of our sites will be completely safe. We encourage you to use caution when using the Internet. This includes not sharing your passwords. If you think that an unauthorized account has been created using your name, contact us at the address below.\n",
      "We are TRUSTe certified.\n",
      "TRUSTe has awarded Live Nation the TRUSTe's Privacy Seal. This means TRUSTe independently reviewed this Policy and the practices on Live Nation and Ticketmaster sites and apps to make sure they meet TRUSTE's requirements. The seal applies to our practices for information collected on U.S., UK, Ireland sites and apps.\n",
      "We keep personal information as long as it is necessary or relevant for our business. We also keep information to resolve disputes, enforce our agreements and as otherwise required by law.\n",
      "We store information both in and outside of the United States. If you live outside of the United States, you understand and agree that we may transfer your information to the United States. This site is subject to U.S. laws, which may not afford the same level of protection of those in your country.\n",
      "Live Nation complies with the U.S.-EU Safe Harbor Framework as set forth by the U.S. Department of Commerce regarding the collection, use and retention of personal information from European Union member countries. Live Nation has certified that it adheres to the Safe Harbor Privacy Principles of notice, choice, onward transfer, security, data integrity, access, and enforcement. To learn more about the Safe Harbor program, and to view Live Nation's certification, please visit http://www.export.gov/safeharbor.\n",
      "We may link to third party sites or services we don't control. If you click on one of those links, you will be taken to websites we do not control. This policy does not apply to the privacy practices of those websites. Read the privacy policy of other websites carefully. We are not responsible for these third party sites.\n",
      "What we will do if there is an update to this policy. From time to time we may change our privacy practices. We will notify you of any material changes to this policy as required by law. We will also post an updated copy on our website. Please check our site periodically for updates.\n"
     ]
    }
   ],
   "source": [
    "import modules.document.utils.policyqa_parser as policyqa_parser\n",
    "\n",
    "policy_doc = policyqa_parser.parse_policy_text_by_title(\"ticketmaster.com\", \"../data/dev.json\")\n",
    "print(f'policy_doc length: {len(policy_doc.text)}')\n",
    "print(policy_doc.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:42.792255Z",
     "start_time": "2024-02-21T11:02:41.375744Z"
    }
   },
   "id": "e1915ce6ff2b5cdb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['ticketmaster.com',\n 'theatlantic.com',\n 'sci-news.com',\n 'yahoo.com',\n 'style.com',\n 'adweek.com',\n 'cariboucoffee.com',\n 'kaleidahealth.org',\n 'fool.com',\n 'buffalowildwings.com',\n 'post-gazette.com',\n 'internetbrands.com',\n 'mlb.mlb.com',\n 'eatchicken.com',\n 'ted.com',\n 'naturalnews.com',\n 'cbsinteractive.com',\n 'washingtonian.com',\n 'dogbreedinfo.com',\n 'walmart.com']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policyqa_parser.get_all_policy_titles(\"../data/dev.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:42.830810Z",
     "start_time": "2024-02-21T11:02:42.793266Z"
    }
   },
   "id": "fa3eb1d836e93fe7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"local.env\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:42.859523Z",
     "start_time": "2024-02-21T11:02:42.830810Z"
    }
   },
   "id": "30b42760262f8126",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai_api_key: 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\n",
      "azure_openai_key: 5c290765f18449559375b6108879be23\n",
      "api_endpoint: http://127.0.0.1:8000/v1\n",
      "api_version: 2023-05-15\n",
      "azure_gpt4_deployment_name: AI4ESGGPT4\n",
      "embedding_model: text-embedding-ada-002\n",
      "chunk_size: 512\n",
      "overlap_size: 0\n",
      "max_content: 3\n",
      "prompt_size: 7000\n",
      "add_title: True\n",
      "answer_do_not_know: False\n",
      "temperature: 0.0001\n",
      "db_user: postgres\n",
      "db_pass: postgres\n",
      "db_host: localhost\n",
      "db_port: 5432\n",
      "db_name: ai4esg\n"
     ]
    }
   ],
   "source": [
    "from config import config\n",
    "\n",
    "for key, value in vars(config).items():\n",
    "    print(f'{key}: {value}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:42.893018Z",
     "start_time": "2024-02-21T11:02:42.860528Z"
    }
   },
   "id": "cb79d64c55aa8ed6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_FILE: ../data/dev.json\n",
      "RESULT_FILE: ../results/dev_results.json\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"dev\"\n",
    "DATASET_FILE = f\"../data/{DATASET}.json\"\n",
    "RESULT_FILE = f\"../results/{DATASET}_results.json\"\n",
    "print(f'DATASET_FILE: {DATASET_FILE}')\n",
    "print(f'RESULT_FILE: {RESULT_FILE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:43.112731Z",
     "start_time": "2024-02-21T11:02:43.109603Z"
    }
   },
   "id": "5ab20203a59e10a0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy title: ticketmaster.com already exists in database\n"
     ]
    }
   ],
   "source": [
    "from modules.document.service import create as create_document\n",
    "from modules.document.service import get_by_title\n",
    "\n",
    "async def save_policy_to_db(policy_doc):\n",
    "    if get_by_title(policy_doc.title):\n",
    "        print(f\"policy title: {policy_doc.title} already exists in database\")\n",
    "        return\n",
    "    policy_obj = await create_document(policy_doc)\n",
    "    return policy_obj\n",
    "\n",
    "async def save_all_policies_to_db(file_path: str=\"../data/dev.json\"):\n",
    "    policy_titles = policyqa_parser.get_all_policy_titles(file_path)\n",
    "    for title in policy_titles:\n",
    "        policy_doc = policyqa_parser.parse_policy_text_by_title(title, file_path)\n",
    "        policy_obj = await save_policy_to_db(policy_doc)\n",
    "        print(f\"saved policy id:{policy_obj.id}, title:{policy_obj.title}, doc_type:{policy_obj.doc_type} to database\")\n",
    "\n",
    "policy_doc = policyqa_parser.parse_policy_text_by_title(\"ticketmaster.com\", \"../data/dev.json\")\n",
    "policy_obj = await save_policy_to_db(policy_doc)\n",
    "if policy_obj:\n",
    "    print(f\"saved policy id:{policy_obj.id}, title:{policy_obj.title}, doc_type:{policy_obj.doc_type} to database\")\n",
    "\n",
    "# Only run this to save all policies to database\n",
    "#await save_all_policies_to_db(DATASET_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:48.154895Z",
     "start_time": "2024-02-21T11:02:43.578331Z"
    }
   },
   "id": "928ec7e1a709688a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai4esg-MyrZEbvC-py3.11\\Lib\\site-packages\\pydantic\\_internal\\_config.py:322: UserWarning: Valid config keys have changed in V2:\n",
      "* 'orm_mode' has been renamed to 'from_attributes'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from modules.answer.schemas import AnswerCreate\n",
    "from modules.llm.llm_infos import Model\n",
    "\n",
    "request = AnswerCreate(\n",
    "    question=\"in ticketmaster.com, Does the collected data reveal my identity?\",\n",
    "    model=Model.Fusion_Net,\n",
    "    prompt=\"Answer the question by copying exactly a portion of the contexts, \"\n",
    "           \"The portion you copy to answer the question should be as short and concise as possible. \"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:02:48.173882Z",
     "start_time": "2024-02-21T11:02:48.155900Z"
    }
   },
   "id": "db3c5952266cffe1",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.9838356971740723\n",
      "We collect information from and about you. Contact information. For example, we might collect your name and street address. We might also collect your phone number or email.\n",
      "num_tokens: 248\n"
     ]
    }
   ],
   "source": [
    "from modules.answer.service import create as create_answer\n",
    "from collections import deque\n",
    "import openai\n",
    "\n",
    "openai.api_key = config.azure_openai_key\n",
    "openai.api_base = config.api_endpoint\n",
    "openai.api_version = config.api_version\n",
    "question_embedding, answer_embeddings, answer_generator, num_tokens = await create_answer(request)\n",
    "answer_text = deque(answer_generator, maxlen=1)[0]\n",
    "\n",
    "print(answer_text)\n",
    "print(f'num_tokens: {num_tokens}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T12:47:51.188420Z",
     "start_time": "2024-02-21T12:47:46.475546Z"
    }
   },
   "id": "ee12ec24cdf9cf7b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from modules.llm.utils import vector_similarity\n",
    "import pprint\n",
    "    \n",
    "def get_relevant_embeddings(answer_embeddings, question_embedding):\n",
    "    relevant_embeddings = {\"data\": []}\n",
    "    for i, embedding in enumerate(answer_embeddings):\n",
    "        relevant_embedding = {}\n",
    "        score = vector_similarity(embedding.values, question_embedding)\n",
    "        relevant_embedding[\"embedding_id\"] = str(embedding.id)\n",
    "        relevant_embedding[\"rank\"] = i+1\n",
    "        relevant_embedding[\"title\"] = embedding.document.title\n",
    "        relevant_embedding[\"offset\"] = embedding.offset\n",
    "        relevant_embedding[\"score\"] = score\n",
    "        relevant_embedding[\"text\"] = embedding.text\n",
    "        relevant_embeddings[\"data\"].append(relevant_embedding)\n",
    "    return relevant_embeddings\n",
    "\n",
    "#pprint.pprint(get_relevant_embeddings(answer_embeddings, question_embedding))\n",
    "#print(get_relevant_embeddings(answer_embeddings, question_embedding))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:47:50.525218400Z",
     "start_time": "2024-02-14T14:47:50.518876900Z"
    }
   },
   "id": "1cce753be1f0dcbe",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average context size is: 430.5452961672474\n",
      "The average answer size is: 70.21095301125082\n",
      "The min answer size is: 2\n",
      "The max answer size is: 1552\n",
      "The min context size is: 24\n",
      "The max context size is: 1598\n"
     ]
    }
   ],
   "source": [
    "min_answer_size, max_answer_size = policyqa_parser.calculate_min_max_answer_size(\"../data/dev.json\")\n",
    "min_context_size, max_context_size = policyqa_parser.calculate_min_max_context_size(\"../data/dev.json\")\n",
    "print(f'The average context size is: {policyqa_parser.calculate_avg_context_size(\"../data/dev.json\")}')\n",
    "print(f'The average answer size is: {policyqa_parser.calculate_avg_answer_size(\"../data/dev.json\")}')\n",
    "print(f'The min answer size is: {min_answer_size}')\n",
    "print(f'The max answer size is: {max_answer_size}')\n",
    "print(f'The min context size is: {min_context_size}')\n",
    "print(f'The max context size is: {max_context_size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:40:40.540814900Z",
     "start_time": "2024-02-14T13:40:40.358201700Z"
    }
   },
   "id": "282a89da3a96df6b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max text size is: 33499 for title: internetbrands.com\n"
     ]
    }
   ],
   "source": [
    "from modules.document.utils.policyqa_parser import get_max_text_size\n",
    "max_text_len, max_text_title = get_max_text_size(\"../data/dev.json\")\n",
    "print(f'The max text size is: {max_text_len} for title: {max_text_title}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:40:45.726940800Z",
     "start_time": "2024-02-14T13:40:45.300644200Z"
    }
   },
   "id": "487f2cf6f9377b7e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'test'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../data/test.json\"\n",
    "file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "file_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:40:48.341303500Z",
     "start_time": "2024-02-14T13:40:48.326402800Z"
    }
   },
   "id": "ce91f84511f4e040",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def count_qas(file_path: str=\"../data/dev.json\"):\n",
    "    count = 0\n",
    "    with open(file_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "        if \"data\" in json_data:\n",
    "            for policy in tqdm(json_data[\"data\"]):\n",
    "                for paragraph in tqdm(policy[\"paragraphs\"]):\n",
    "                    for qa in paragraph[\"qas\"]:\n",
    "                        count += 1\n",
    "                        time.sleep(0.001)\n",
    "    return count\n",
    "\n",
    "\n",
    "#qa_count = count_qas(\"../data/dev.json\")\n",
    "#print(f'total number of qas is: {qa_count}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:40:51.120307900Z",
     "start_time": "2024-02-14T13:40:51.042448200Z"
    }
   },
   "id": "d343d20421e4b8f7",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "rate_limit_per_minute = 9600 # values from azure\n",
    "tokens_per_minute = 40000 # values from azure\n",
    "delay = 60.0 / rate_limit_per_minute\n",
    "\n",
    "def get_saved_qas(file_path: str):\n",
    "    saved_qas = []\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            if \"data\" in json_data:\n",
    "                for qa in json_data[\"data\"]:\n",
    "                    saved_qas.append(qa[\"id\"])\n",
    "    return saved_qas\n",
    "\n",
    "async def run_all_policy_qas(file_path: str=\"../data/dev.json\", model: Model=Model.Gpt4):\n",
    "    running_tokens = 0\n",
    "    start_time = time.time()\n",
    "    results = {\"data\": []}\n",
    "    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    # check if there are saved results and load them\n",
    "    saved_qas = get_saved_qas(f\"../results/{file_name}_results.json\")\n",
    "    if len(saved_qas) > 0:\n",
    "        with open(f\"../results/{file_name}_results.json\", \"r\") as f:\n",
    "            results = json.load(f)\n",
    "        \n",
    "    with open(file_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "        if \"data\" in json_data:\n",
    "            for policy in tqdm(json_data[\"data\"]):\n",
    "                title = policy[\"title\"]\n",
    "                logging.info(f\"processing policy: {title}\")\n",
    "                for i, paragraph in tqdm(enumerate(policy[\"paragraphs\"])):\n",
    "                    for qa in paragraph[\"qas\"]:\n",
    "                        q_id = qa[\"id\"]\n",
    "                        if q_id in saved_qas:\n",
    "                            #print(f\"skipping question {q_id} because it is already saved\")\n",
    "                            continue\n",
    "                        question = qa[\"question\"]\n",
    "                        answers = qa[\"answers\"]\n",
    "                        request = AnswerCreate(\n",
    "                            question=f'in {title}, {question}',\n",
    "                            model=model,\n",
    "                            prompt=\"Answer the question by copying exactly a portion of the contexts, \"\n",
    "                                   \"The portion you copy to answer the question should be as short and concise as possible.\"\n",
    "                        )\n",
    "\n",
    "                        if running_tokens > tokens_per_minute*0.8 and time.time() - start_time < 60.0:\n",
    "                            time.sleep((time.time() - start_time)+15)\n",
    "                            start_time = time.time()\n",
    "                            running_tokens = 0\n",
    "                        \n",
    "                        question_embedding, answer_embeddings, answer_generator, num_tokens = await create_answer(request)\n",
    "                        \n",
    "                        running_tokens += num_tokens\n",
    "                        \n",
    "                        time.sleep(delay)\n",
    "                        answer_text = deque(answer_generator, maxlen=1)[0]\n",
    "                        relevant_embeddings = get_relevant_embeddings(answer_embeddings, question_embedding)\n",
    "                        results[\"data\"].append({\n",
    "                            \"title\": title,\n",
    "                            \"id\": q_id,\n",
    "                            \"question\": question,\n",
    "                            \"answers\": answers,\n",
    "                            \"pred_answer\": answer_text,\n",
    "                            \"relevant_embeddings\": relevant_embeddings[\"data\"]\n",
    "                        })\n",
    "                    # save results to file after each paragraph\n",
    "                    with open(f\"../results/{file_name}_results.json\", \"w\") as f:\n",
    "                        json.dump(results, f, indent=4)\n",
    "                        print(f\"saved results to ../results/{file_name}_results.json for title {title} paragraph {i}\")\n",
    "                        \n",
    "        \n",
    "        \n",
    "async def run_all_policy_qas_dev():\n",
    "    await run_all_policy_qas(\"../data/dev.json\")\n",
    "    \n",
    "async def run_all_policy_qas_test():\n",
    "    await run_all_policy_qas(\"../data/test.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T07:54:14.244642900Z",
     "start_time": "2024-01-19T07:54:14.241639500Z"
    }
   },
   "id": "488800503ea97b93",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#test GPT-4 responses with small dataset\n",
    "\n",
    "await run_all_policy_qas(DATASET_FILE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89275a3a39f4482",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#get all responses for the dev dataset\n",
    "\n",
    "# await run_all_policy_qas_dev()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acc9bba7ec340421",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3809/3809 [00:00<00:00, 634955.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'exact_match': tensor(2.2316), 'f1': tensor(17.1876)}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from backend.evals.torchmetrics_eval_script import eval_squad_metrics\n",
    "\n",
    "eval_squad_metrics(RESULT_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:47:01.970067400Z",
     "start_time": "2024-01-19T10:46:27.380950Z"
    }
   },
   "id": "6262e632afafcc0b",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 2.2053032291940142\n",
      " F1-measure: 17.32493191877359\n",
      " Precision: 14.149706626319325\n",
      " Recall: 52.3996207502066\n"
     ]
    }
   ],
   "source": [
    "from backend.evals.squad_eval_script import Evaluator\n",
    "import json\n",
    "\n",
    "evaluator = Evaluator(DATASET_FILE)\n",
    "em, f1, precision, recall = evaluator.evaluate(RESULT_FILE)\n",
    "print(f\"Exact Match: {em}\\n F1-measure: {f1}\\n Precision: {precision}\\n Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:47:16.607267Z",
     "start_time": "2024-01-19T10:47:16.353028800Z"
    }
   },
   "id": "ea8670ed0a77bb97",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3809it [00:00, 361090.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7618\n",
      "7618\n",
      "7618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from backend.evals.torchmetrics_eval_script import prepare_retrieval_data\n",
    "top_k=2\n",
    "_, indexes, preds, labels = prepare_retrieval_data(RESULT_FILE, top_k=top_k)\n",
    "print(len(indexes))\n",
    "print(len(preds))\n",
    "print(len(labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:47:34.140640800Z",
     "start_time": "2024-01-19T10:47:33.994783600Z"
    }
   },
   "id": "dbbb160afdbe41e1",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7])\n",
      "tensor([0.8522, 0.8476, 0.8588, 0.8567, 0.8354, 0.8327, 0.8566, 0.8539, 0.8520,\n",
      "        0.8445, 0.8627, 0.8576, 0.8507, 0.8434, 0.8658])\n",
      "tensor([False, False, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True, False,  True, False,\n",
      "         True, False, False,  True,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False, False,  True, False,  True, False,  True,\n",
      "         True, False,  True, False,  True, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "print(indexes[0:15])\n",
    "print(preds[0:15])\n",
    "print(labels[0:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:47:37.047439200Z",
     "start_time": "2024-01-19T10:47:37.025579300Z"
    }
   },
   "id": "2f97b595166c99eb",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "3809it [00:00, 634324.78it/s]\n",
      "\n",
      "  0%|          | 0/3809 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|▌         | 233/3809 [00:00<00:01, 2317.76it/s]\u001B[A\n",
      " 13%|█▎        | 480/3809 [00:00<00:01, 2403.53it/s]\u001B[A\n",
      " 19%|█▉        | 736/3809 [00:00<00:01, 2469.00it/s]\u001B[A\n",
      " 26%|██▌       | 983/3809 [00:00<00:01, 2400.76it/s]\u001B[A\n",
      " 32%|███▏      | 1224/3809 [00:00<00:01, 2300.85it/s]\u001B[A\n",
      " 38%|███▊      | 1455/3809 [00:00<00:01, 2193.88it/s]\u001B[A\n",
      " 44%|████▍     | 1676/3809 [00:00<00:01, 2104.23it/s]\u001B[A\n",
      " 50%|████▉     | 1888/3809 [00:00<00:00, 2021.93it/s]\u001B[A\n",
      " 55%|█████▍    | 2091/3809 [00:00<00:00, 1979.07it/s]\u001B[A\n",
      " 60%|██████    | 2290/3809 [00:01<00:00, 1897.94it/s]\u001B[A\n",
      " 65%|██████▌   | 2481/3809 [00:01<00:00, 1810.58it/s]\u001B[A\n",
      " 70%|██████▉   | 2663/3809 [00:01<00:00, 1752.54it/s]\u001B[A\n",
      " 75%|███████▍  | 2839/3809 [00:01<00:00, 1686.79it/s]\u001B[A\n",
      " 79%|███████▉  | 3008/3809 [00:01<00:00, 1612.41it/s]\u001B[A\n",
      " 83%|████████▎ | 3170/3809 [00:01<00:00, 1573.76it/s]\u001B[A\n",
      " 87%|████████▋ | 3328/3809 [00:01<00:00, 1516.67it/s]\u001B[A\n",
      " 91%|█████████▏| 3480/3809 [00:01<00:00, 1432.08it/s]\u001B[A\n",
      " 95%|█████████▌| 3624/3809 [00:02<00:00, 1383.35it/s]\u001B[A\n",
      "100%|██████████| 3809/3809 [00:02<00:00, 1772.53it/s]\u001B[A\n",
      "C:\\Users\\onan\\IdeaProjects\\ai4esg_experiments_new\\backend\\evals\\torchmetrics_eval_script.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  relevant_embeddings_ratio = torch.tensor(sum(targets) / len(targets))\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.49s/it]\n",
      "3809it [00:00, 365268.28it/s]\n",
      "\n",
      "  0%|          | 0/3809 [00:00<?, ?it/s]\u001B[A\n",
      "  7%|▋         | 276/3809 [00:00<00:01, 2742.99it/s]\u001B[A\n",
      " 14%|█▍        | 551/3809 [00:00<00:01, 2505.91it/s]\u001B[A\n",
      " 21%|██        | 803/3809 [00:00<00:01, 2507.54it/s]\u001B[A\n",
      " 28%|██▊       | 1055/3809 [00:00<00:01, 2353.43it/s]\u001B[A\n",
      " 34%|███▍      | 1292/3809 [00:00<00:01, 2248.60it/s]\u001B[A\n",
      " 40%|███▉      | 1518/3809 [00:00<00:01, 2135.44it/s]\u001B[A\n",
      " 45%|████▌     | 1733/3809 [00:00<00:01, 2035.57it/s]\u001B[A\n",
      " 51%|█████     | 1938/3809 [00:00<00:00, 1989.09it/s]\u001B[A\n",
      " 56%|█████▌    | 2138/3809 [00:01<00:00, 1905.32it/s]\u001B[A\n",
      " 61%|██████    | 2329/3809 [00:01<00:00, 1859.71it/s]\u001B[A\n",
      " 66%|██████▌   | 2516/3809 [00:01<00:00, 1793.54it/s]\u001B[A\n",
      " 71%|███████   | 2696/3809 [00:01<00:00, 1731.10it/s]\u001B[A\n",
      " 75%|███████▌  | 2870/3809 [00:01<00:00, 1652.82it/s]\u001B[A\n",
      " 80%|███████▉  | 3036/3809 [00:01<00:00, 1599.13it/s]\u001B[A\n",
      " 84%|████████▍ | 3197/3809 [00:01<00:00, 1573.87it/s]\u001B[A\n",
      " 88%|████████▊ | 3355/3809 [00:01<00:00, 1513.31it/s]\u001B[A\n",
      " 92%|█████████▏| 3507/3809 [00:01<00:00, 1454.76it/s]\u001B[A\n",
      " 96%|█████████▌| 3653/3809 [00:02<00:00, 1420.99it/s]\u001B[A\n",
      "100%|██████████| 3809/3809 [00:02<00:00, 1774.42it/s]\u001B[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.51s/it]\n",
      "3809it [00:00, 253500.43it/s]\n",
      "\n",
      "  0%|          | 0/3809 [00:00<?, ?it/s]\u001B[A\n",
      "  7%|▋         | 275/3809 [00:00<00:01, 2746.43it/s]\u001B[A\n",
      " 14%|█▍        | 550/3809 [00:00<00:01, 2390.11it/s]\u001B[A\n",
      " 21%|██        | 792/3809 [00:00<00:01, 2388.50it/s]\u001B[A\n",
      " 27%|██▋       | 1033/3809 [00:00<00:01, 2289.03it/s]\u001B[A\n",
      " 33%|███▎      | 1264/3809 [00:00<00:01, 2187.72it/s]\u001B[A\n",
      " 39%|███▉      | 1484/3809 [00:00<00:01, 2094.97it/s]\u001B[A\n",
      " 44%|████▍     | 1695/3809 [00:00<00:01, 1963.48it/s]\u001B[A\n",
      " 50%|████▉     | 1893/3809 [00:00<00:01, 1906.42it/s]\u001B[A\n",
      " 55%|█████▍    | 2085/3809 [00:01<00:00, 1800.73it/s]\u001B[A\n",
      " 59%|█████▉    | 2266/3809 [00:01<00:00, 1749.94it/s]\u001B[A\n",
      " 64%|██████▍   | 2442/3809 [00:01<00:00, 1750.10it/s]\u001B[A\n",
      " 69%|██████▊   | 2618/3809 [00:01<00:00, 1660.56it/s]\u001B[A\n",
      " 73%|███████▎  | 2785/3809 [00:01<00:00, 1622.05it/s]\u001B[A\n",
      " 77%|███████▋  | 2948/3809 [00:01<00:00, 1577.37it/s]\u001B[A\n",
      " 82%|████████▏ | 3106/3809 [00:01<00:00, 1513.17it/s]\u001B[A\n",
      " 86%|████████▌ | 3258/3809 [00:01<00:00, 1414.96it/s]\u001B[A\n",
      " 89%|████████▉ | 3401/3809 [00:01<00:00, 1378.07it/s]\u001B[A\n",
      " 93%|█████████▎| 3540/3809 [00:02<00:00, 1348.78it/s]\u001B[A\n",
      " 97%|█████████▋| 3676/3809 [00:02<00:00, 1319.36it/s]\u001B[A\n",
      "100%|██████████| 3809/3809 [00:02<00:00, 1688.10it/s]\u001B[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map@1': tensor(0.4067), 'mrr@1': tensor(0.4067), '%Answers found@1': tensor(0.4067), '%Relevant embeddings@1': tensor(0.4067)}\n",
      "{'map@2': tensor(0.4794), 'mrr@2': tensor(0.4794), '%Answers found@2': tensor(0.5521), '%Relevant embeddings@2': tensor(0.3584)}\n",
      "{'map@3': tensor(0.5129), 'mrr@3': tensor(0.5155), '%Answers found@3': tensor(0.6605), '%Relevant embeddings@3': tensor(0.3325)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from backend.evals.torchmetrics_eval_script import eval_retrieval_metrics\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# logging.disable(logging.INFO)\n",
    "\n",
    "retrieval_metrics = []\n",
    "top_k=config.max_content\n",
    "for i in tqdm(range(1, top_k+1)):\n",
    "    retrieval_metrics.append(eval_retrieval_metrics(RESULT_FILE, top_k=i))\n",
    "\n",
    "for retrieval_metrics in retrieval_metrics:\n",
    "    print(f'{retrieval_metrics}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:47:50.017094700Z",
     "start_time": "2024-01-19T10:47:42.148178700Z"
    }
   },
   "id": "e995ad44a10787c8",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from backend.evals.torchmetrics_eval_script import eval_retrieval_metrics\n",
    "top_k=5\n",
    "retrieval_metrics = eval_retrieval_metrics(\"../results/dev_results.json\", top_k=top_k)\n",
    "print(f'The retrieval metrics @{top_k} are {retrieval_metrics}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46587ee4162a8970",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import modules.document.utils.policyqa_parser as policyqa_parser\n",
    "\n",
    "num_answers = policyqa_parser.count_answers(\"../data/dev.json\")\n",
    "num_answers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c78b3adb079a1dca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from backend.modules.document.utils.policyqa_parser import count_questions\n",
    "\n",
    "print(count_questions(\"../data/dev.json\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41d72ed3062bee82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ab4ab5ab65c6ab6c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
