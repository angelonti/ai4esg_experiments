{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:32:36.997506Z",
     "start_time": "2024-02-22T15:32:36.991938Z"
    }
   },
   "outputs": [],
   "source": [
    "# mistralai/Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:32:44.572631Z",
     "start_time": "2024-02-22T15:32:36.998510Z"
    }
   },
   "id": "154e6a1a39e97588",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA RTX A3000 12GB Laptop GPU'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:32:44.578688Z",
     "start_time": "2024-02-22T15:32:44.574647Z"
    }
   },
   "id": "40f6741364053468",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "print(os.environ.get(\"DISABLE_QIGEN\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:47.899186Z",
     "start_time": "2024-02-22T15:33:47.883225Z"
    }
   },
   "id": "66654746d017d82f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA RTX A3000 12GB Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:48.345653Z",
     "start_time": "2024-02-22T15:33:48.340772Z"
    }
   },
   "id": "c666a76daec8913",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:49.874570Z",
     "start_time": "2024-02-22T15:33:49.830661Z"
    }
   },
   "id": "5e2f47fc09364272",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A3000 12GB Laptop GPU\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:50.814427Z",
     "start_time": "2024-02-22T15:33:50.810427Z"
    }
   },
   "id": "578d4006d9041472",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#model_id = \"yunconglong/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B\" # 129s 50 token\n",
    "#model_id = \"mistralai/Mistral-7B-Instruct-v0.2\" # 25s 50 token\n",
    "#model_id = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\" #2.5s 50 token\n",
    "model_id = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\" #33s 50 token\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:53.756810Z",
     "start_time": "2024-02-22T15:33:51.806550Z"
    }
   },
   "id": "597f55e14f6dd782",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1000000000000000019884624838656"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:54.903198Z",
     "start_time": "2024-02-22T15:33:54.899164Z"
    }
   },
   "id": "761720a40a9e39f1",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"yunconglong/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B\" # 129s 50 token\n",
    "\"mistralai/Mistral-7B-Instruct-v0.2\" # 25s 50 token\n",
    "\"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\" #2.5s 50 token\n",
    "\"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\" #33s 50 token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:33:55.781455Z",
     "start_time": "2024-02-22T15:33:55.777756Z"
    }
   },
   "id": "73e601982d07a5d",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda:0\",\n",
    "    trust_remote_code=False,\n",
    "    revision=\"main\",\n",
    "    #torch_dtype=torch.float16,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:35:24.736290Z",
     "start_time": "2024-02-22T15:33:58.256752Z"
    }
   },
   "id": "3fbb7367b5dbce3f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:35:43.483189Z",
     "start_time": "2024-02-22T15:35:43.458270Z"
    }
   },
   "id": "15a02e88f9750658",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 35.67814636230469\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "text = \"Tell me about Venezuela\"\n",
    "prompt_template=f'''[INST] {text} [/INST]'''\n",
    "inputs = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.to(0)\n",
    "outputs = model.generate(inputs, max_new_tokens=50, do_sample=True, temperature=0.01)\n",
    "\n",
    "print(f\"Time: {time.time() - start_time}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:36:19.746781Z",
     "start_time": "2024-02-22T15:35:44.063331Z"
    }
   },
   "id": "dacf08b58f40c52b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T12:41:17.851283Z",
     "start_time": "2024-02-16T12:41:17.847475Z"
    }
   },
   "id": "bd7e1d65fa146372",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venezuela is a country located in the northern part of South America. It is the westernmost country of the South American region, and it is bordered by Colombia to the west, Brazil to the south and the Atlantic Ocean to the north. The capital city is Caracas.\n",
      "\n",
      "Venezuela has a rich cultural heritage, with indigenous, European, African, and Asian influences. The country is known for its natural beauty, with diverse landscapes ranging from the Andes Mountains in the west to the Amazon Rainforest in the south, and the Caribbean Sea coastline in the north.\n",
      "\n",
      "Venezuela is the world's largest holder of oil reserves, and its economy has historically been heavily dependent on the oil industry. However, the country has faced significant economic challenges in recent years, including hyperinflation, food shortages, and a decline in living standards for many of its people.\n",
      "\n",
      "Politically, Venezuela has a presidential representative democratic republic, with the President of Venezuela serving as both head of state and government. The country has a complex and often tumultuous political history, with periods of authoritarian rule, political instability, and social unrest.\n",
      "\n",
      "In recent years, Venezuela has been mired in a deep political and humanitarian crisis, with widespread protests, food shortages, and a massive exodus of refugees. The situation has been compounded by the COVID-19 pandemic, which has put additional strain on the country's already fragile healthcare system and economy.\n",
      "\n",
      "Despite these challenges, Venezuela remains a diverse and vibrant country with a rich cultural heritage and a proud people. It is home to numerous indigenous communities, as well as a large diaspora population living abroad. Venezuela is also known for its music, art, and literature, and is a popular tourist destination for its natural beauty and rich cultural offerings.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0][inputs.size()[1]:], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T12:41:18.405534Z",
     "start_time": "2024-02-16T12:41:18.399111Z"
    }
   },
   "id": "20667aaf7b430950",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "from config import config\n",
    "\n",
    "##this function can eventually be used to serve gptq models\n",
    "def get_completion_gptq(self, prompt) -> Generator[str, None, None]:\n",
    "    model_id = self.GPTQ_MODEL_FILE_MAPPING[self.model.value]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "    self.gptq_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=False,\n",
    "        revision=\"main\",\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    prompt_template = f'''{self.priming} \\n\\n {prompt}'''\n",
    "    inputs = tokenizer(prompt_template, return_tensors=\"pt\").input_ids\n",
    "    outputs = self.gptq_model.generate(inputs, max_new_tokens=config.prompt_size, do_sample=True,\n",
    "                                       temperature=config.temperature)\n",
    "    print(f\"Time: {time.time() - start_time}\")\n",
    "    yield tokenizer.decode(outputs[0][inputs.size()[1]:], skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef8156a8205f20ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
